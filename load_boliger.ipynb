{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this to work we need to have Phantom installed (https://stackoverflow.com/questions/8049520/web-scraping-javascript-page-with-python) in order to be able to render javascript content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import urllib\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_adress_data(pickle_path='data/adresses/copenhagen_adresses.pickle', raw_path='http://dawa.aws.dk/adresser?format=csv&kommunekode=0101'):\n",
    "    try: \n",
    "        print('Loading from pickle')\n",
    "        df_adress = pd.read_pickle(pickle_path)\n",
    "    except:\n",
    "        print(f'Loading from pickle failed. Loading from source ({raw_path}) instead')\n",
    "        address_path = raw_path     #address_path = 'http://dawa.aws.dk/adresser?format=json&kommunekode=0101'\n",
    "        with urllib.request.urlopen(address_path) as f:\n",
    "            data_binary = f.readlines() #.decode()\n",
    "        data = [re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', x.decode().strip()).split(',') for x in data_binary] # https://stackoverflow.com/questions/38336518/remove-all-commas-between-quotes\n",
    "        df_adress = pd.DataFrame(data[1:], columns=data[0])\n",
    "        df.to_pickle(pickle_path)\n",
    "    return df_adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pickle\n"
     ]
    }
   ],
   "source": [
    "df_adress = read_adress_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.boliga.dk/resultat?sort=zipCode-a&municipality=101&page=1\n"
     ]
    }
   ],
   "source": [
    "bolig_liste = defaultdict(str)\n",
    "\n",
    "for page in range(1,2):\n",
    "    url_in_scope = f'https://www.boliga.dk/resultat?sort=zipCode-a&municipality=101&page={page}'\n",
    "    print('Scraping', url_in_scope)\n",
    "    try:\n",
    "        page = urllib.request.urlopen(url_in_scope)\n",
    "        #soup = BeautifulSoup(page, 'html.parser')\n",
    "        #print(soup)\n",
    " \n",
    "        for link in BeautifulSoup(page, 'html.parser', parse_only=SoupStrainer('a')):\n",
    "\n",
    "            if link.has_attr('href'):\n",
    "                #print(link['href'])\n",
    "                if re.match('/bolig/\\d*/.*', link['href']):\n",
    "                    bolig_liste[link['href']] = defaultdict(str)\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "            print(\"An error occured.\", e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bolig_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.boliga.dk/bolig/1616756/tyboroen_alle_91__st_2720_vanloese\n"
     ]
    }
   ],
   "source": [
    "for i, bolig in enumerate(bolig_liste.keys()):\n",
    "    if i == 0:\n",
    "        bolig_url = f'https://www.boliga.dk{bolig}'\n",
    "        print(bolig_url)\n",
    "        \n",
    "        try:\n",
    "            page = urllib.request.urlopen(url_in_scope)\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            #print(soup)\n",
    "            #body = soup.find('body')\n",
    "            #body_no_tags = body.findChildren(recursive=False)\n",
    "            #print(body_no_tags)\n",
    "            tags = {tag.name: 1 for tag in soup.find_all()}\n",
    "#            [str(tag) for tag in soup.find_all()]\n",
    "        except Exception as e:\n",
    "            print(\"An error occured.\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Interesting, found Marievej in html\n",
      "      Interesting, found 33.291 in html\n",
      "      Interesting, found mar. 2020 in html\n",
      "      Interesting, found Boligen blev sat til salg in html\n",
      "      Interesting, found 120 in html\n",
      "      Interesting, found 2500 Valby in html\n",
      "      Interesting, found 2500 Valby in html\n",
      "      Interesting, found Se bolig hos mægler in html\n",
      "      Interesting, found Marievej in body\n",
      "      Interesting, found 33.291 in body\n",
      "      Interesting, found mar. 2020 in body\n",
      "      Interesting, found 120 in body\n",
      "      Interesting, found 2500 Valby in body\n",
      "      Interesting, found 2500 Valby in body\n",
      "      Interesting, found Marievej in body\n",
      "      Interesting, found Boligen blev sat til salg in body\n",
      "      Interesting, found 120 in body\n",
      "      Interesting, found Se bolig hos mægler in body\n",
      "      Interesting, found Marievej in app-root\n",
      "      Interesting, found 33.291 in app-root\n",
      "      Interesting, found mar. 2020 in app-root\n",
      "      Interesting, found 120 in app-root\n",
      "      Interesting, found 2500 Valby in app-root\n",
      "      Interesting, found 2500 Valby in app-root\n",
      "      Interesting, found Marievej in app-scroll-position-restoration\n",
      "      Interesting, found 33.291 in app-scroll-position-restoration\n",
      "      Interesting, found mar. 2020 in app-scroll-position-restoration\n",
      "      Interesting, found 120 in app-scroll-position-restoration\n",
      "      Interesting, found 2500 Valby in app-scroll-position-restoration\n",
      "      Interesting, found 2500 Valby in app-scroll-position-restoration\n",
      "      Interesting, found Marievej in app-housing-list\n",
      "      Interesting, found 33.291 in app-housing-list\n",
      "      Interesting, found mar. 2020 in app-housing-list\n",
      "      Interesting, found 120 in app-housing-list\n",
      "      Interesting, found 2500 Valby in app-housing-list\n",
      "      Interesting, found 2500 Valby in app-housing-list\n",
      "      Interesting, found Marievej in app-housing-list-results\n",
      "      Interesting, found 33.291 in app-housing-list-results\n",
      "      Interesting, found mar. 2020 in app-housing-list-results\n",
      "      Interesting, found 120 in app-housing-list-results\n",
      "      Interesting, found 2500 Valby in app-housing-list-results\n",
      "      Interesting, found 2500 Valby in app-housing-list-results\n"
     ]
    }
   ],
   "source": [
    "[str(tag_v) for tag_v in soup.find('html')][2]\n",
    "\n",
    "look_for_list = ['Marievej', '4.940', '4.945.000', '33.291', 'mar. 2020', 'Boligen blev sat til salg', \n",
    "                 '120', '2500 Valby', '2500 Valby','7 dage på markedet', 'Se bolig hos mægler', 'danbolig']\n",
    "\n",
    "for t in list(tags):\n",
    "    #print('tag', t)\n",
    "    tag_values = [str(tag_v) for tag_v in soup.find(t)]\n",
    "    for j, tag_v in enumerate(tag_values):\n",
    "        #print(j)\n",
    "        #if j < 2:\n",
    "        for lookout in look_for_list:\n",
    "            if lookout in tag_v:\n",
    "                print(' '*5, 'Interesting, found', lookout, 'in', t)\n",
    "#         if tag_v in\n",
    "#             print(' '*5, j, tag_v)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information seems to be missing. Maybe it's because some javascript is not yet calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolig_url = 'https://www.boliga.dk/bolig/1644897/ingrid_marievej_66__12_4_2500_valby'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 80.0.3987.106 win32] driver in cache \n",
      "File found in cache by path [C:\\Users\\theone\\.wdm\\drivers\\chromedriver\\80.0.3987.106\\win32\\chromedriver.exe]\n"
     ]
    }
   ],
   "source": [
    "# Try 2 - \n",
    "# https://stackoverflow.com/questions/29404856/how-can-i-render-javascript-html-to-html-in-python \n",
    "# https://stackoverflow.com/questions/29858752/error-message-chromedriver-executable-needs-to-be-available-in-the-path\n",
    "\n",
    "from selenium import webdriver\n",
    "from urllib.request import urlopen\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "\n",
    "url = bolig_url# 'http://www.google.com'\n",
    "file_name = 'C:/working/ngs-lib/Boligsalg/data/url_data/data.txt'\n",
    "\n",
    "conn = urlopen(url)\n",
    "data = conn.read()\n",
    "conn.close()\n",
    "\n",
    "file = open(file_name,'wb')\n",
    "file.write(data)\n",
    "file.close()\n",
    "\n",
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "#browser = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "\n",
    "#browser = webdriver.Chrome()\n",
    "browser.get('file:///'+file_name)\n",
    "#browser.get(url)\n",
    "html = browser.page_source\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_for_list = ['Marievej',\n",
    "                     '4.672',\n",
    "                     '4.945.000',\n",
    "                     '250.000',\n",
    "                     '43.377',\n",
    "                     'mar. 2020',\n",
    "                     'Boligen blev sat til salg',\n",
    "                     'A20',\n",
    "                     '114',\n",
    "                     '2500 Valby',\n",
    "                     '6 dage på markedet',\n",
    "                     'Se bolig hos mægler',\n",
    "                     'danbolig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "tags = {tag.name: 1 for tag in soup.find_all()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag html\n",
      "0\n",
      "1\n",
      "      Interesting, found Marievej in html\n",
      "      Interesting, found 4.672 in html\n",
      "      Interesting, found 4.945.000 in html\n",
      "      Interesting, found 250.000 in html\n",
      "      Interesting, found 43.377 in html\n",
      "      Interesting, found mar. 2020 in html\n",
      "      Interesting, found Boligen blev sat til salg in html\n",
      "      Interesting, found A20 in html\n",
      "      Interesting, found 114 in html\n",
      "      Interesting, found 2500 Valby in html\n",
      "      Interesting, found 6 dage på markedet in html\n",
      "      Interesting, found Se bolig hos mægler in html\n",
      "      Interesting, found danbolig in html\n",
      "tag head\n",
      "tag body\n",
      "0\n",
      "      Interesting, found Marievej in body\n",
      "      Interesting, found 4.672 in body\n",
      "      Interesting, found 4.945.000 in body\n",
      "      Interesting, found 250.000 in body\n",
      "      Interesting, found 43.377 in body\n",
      "      Interesting, found mar. 2020 in body\n",
      "      Interesting, found Boligen blev sat til salg in body\n",
      "      Interesting, found A20 in body\n",
      "      Interesting, found 114 in body\n",
      "      Interesting, found 2500 Valby in body\n",
      "      Interesting, found 6 dage på markedet in body\n",
      "      Interesting, found Se bolig hos mægler in body\n",
      "      Interesting, found danbolig in body\n",
      "tag pre\n",
      "0\n",
      "      Interesting, found Marievej in pre\n",
      "      Interesting, found 4.672 in pre\n",
      "      Interesting, found 4.945.000 in pre\n",
      "      Interesting, found 250.000 in pre\n",
      "      Interesting, found 43.377 in pre\n",
      "      Interesting, found mar. 2020 in pre\n",
      "      Interesting, found Boligen blev sat til salg in pre\n",
      "      Interesting, found A20 in pre\n",
      "      Interesting, found 114 in pre\n",
      "      Interesting, found 2500 Valby in pre\n",
      "      Interesting, found 6 dage på markedet in pre\n",
      "      Interesting, found Se bolig hos mægler in pre\n",
      "      Interesting, found danbolig in pre\n"
     ]
    }
   ],
   "source": [
    "for t in list(tags):\n",
    "    print('tag', t)\n",
    "    tag_values = [str(tag_v) for tag_v in soup.find(t)]\n",
    "    for j, tag_v in enumerate(tag_values):\n",
    "        print(j, l)\n",
    "        #if j < 2:\n",
    "        for lookout in look_for_list:\n",
    "            if lookout in tag_v:\n",
    "                print(' '*5, 'Interesting, found', lookout, 'in', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marievej is apparant\n",
      "4.672 is apparant\n",
      "4.945.000 is apparant\n",
      "250.000 is apparant\n",
      "43.377 is apparant\n",
      "mar. 2020 is apparant\n",
      "Boligen blev sat til salg is apparant\n",
      "A20 is apparant\n",
      "114 is apparant\n",
      "2500 Valby is apparant\n",
      "6 dage på markedet is apparant\n",
      "Se bolig hos mægler is apparant\n",
      "danbolig is apparant\n"
     ]
    }
   ],
   "source": [
    "for interest in look_for_list:\n",
    "    #print(interest)\n",
    "    if interest in html:\n",
    "        print(interest, 'is apparant')\n",
    "    else:\n",
    "        print(interest, 'not found :()')\n",
    "\n",
    "#html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY 1: Fialing.. ..\n",
    "\n",
    "#soup = BeautifulSoup(page, 'html.parser')\n",
    "#print(soup)\n",
    "\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/8049520/web-scraping-javascript-page-with-python\n",
    "from requests_html import HTMLSession, AsyncHTMLSession\n",
    "\n",
    "# session = HTMLSession()\n",
    "# r = session.get(bolig_url)\n",
    "# r.html.render()\n",
    "\n",
    "\n",
    "import asyncio\n",
    "if asyncio.get_event_loop().is_running(): # Only patch if needed (i.e. running in Notebook, Spyder, etc)\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "\n",
    "session = AsyncHTMLSession()\n",
    "r = await session.get(bolig_url)\n",
    "#await r.html.arender()\n",
    "#resp=r.html.raw_html\n",
    "#print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
